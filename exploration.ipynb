{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba302082",
   "metadata": {},
   "source": [
    "# üîç CryptoSense - Data Exploration Notebook\n",
    "\n",
    "This notebook explores the cryptocurrency data before modeling.\n",
    "\n",
    "**Why explore first?**\n",
    "- Understand data distributions\n",
    "- Identify missing values and outliers\n",
    "- Discover patterns and relationships\n",
    "- Make informed feature engineering decisions\n",
    "\n",
    "Real data scientists always explore before modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db20357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844479fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "from config import *\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Lookback window: {LOOKBACK_WINDOW} days\")\n",
    "print(f\"Train/Val/Test split: {TRAIN_SPLIT}/{VAL_SPLIT}/{TEST_SPLIT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce93ca52",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data\n",
    "\n",
    "Let's load the raw Bitcoin data and see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ff72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BTC raw data\n",
    "btc_file = os.path.join(RAW_DATA_DIR, 'btc_usd_raw.csv')\n",
    "\n",
    "if os.path.exists(btc_file):\n",
    "    df_raw = pd.read_csv(btc_file)\n",
    "    df_raw['date'] = pd.to_datetime(df_raw['date'])\n",
    "    print(f\"‚úÖ Loaded {len(df_raw)} rows of BTC data\")\n",
    "    print(f\"Date range: {df_raw['date'].min()} to {df_raw['date'].max()}\")\n",
    "else:\n",
    "    print(\"‚ùå Raw data not found. Run data_collection.py first!\")\n",
    "    df_raw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "if df_raw is not None:\n",
    "    display(df_raw.head(10))\n",
    "    display(df_raw.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "if df_raw is not None:\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(\"=\"*60)\n",
    "    df_raw.info()\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    display(df_raw.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d256f66",
   "metadata": {},
   "source": [
    "## 2. Missing Values Analysis\n",
    "\n",
    "Check for missing data and understand gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None:\n",
    "    missing = df_raw.isnull().sum()\n",
    "    missing_pct = (missing / len(df_raw)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    }).sort_values('Missing Count', ascending=False)\n",
    "    \n",
    "    print(\"Missing Values:\")\n",
    "    display(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    # Visualize\n",
    "    if missing.sum() > 0:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        missing[missing > 0].plot(kind='barh')\n",
    "        plt.title('Missing Values by Column')\n",
    "        plt.xlabel('Count')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚úÖ No missing values in raw price data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3314e",
   "metadata": {},
   "source": [
    "## 3. Price Visualization\n",
    "\n",
    "Visualize the price history with volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f63155",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None:\n",
    "    # Interactive candlestick chart\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.03,\n",
    "        subplot_titles=('BTC Price', 'Volume'),\n",
    "        row_heights=[0.7, 0.3]\n",
    "    )\n",
    "    \n",
    "    # Candlestick\n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x=df_raw['date'],\n",
    "            open=df_raw['open'],\n",
    "            high=df_raw['high'],\n",
    "            low=df_raw['low'],\n",
    "            close=df_raw['close'],\n",
    "            name='Price'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Volume\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=df_raw['date'], y=df_raw['volume'], name='Volume', marker_color='lightblue'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Bitcoin Price History and Volume',\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        height=700\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd66ca9",
   "metadata": {},
   "source": [
    "## 4. Returns Analysis\n",
    "\n",
    "Calculate and analyze daily returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72399c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None:\n",
    "    # Calculate returns\n",
    "    df_raw['daily_return'] = df_raw['close'].pct_change()\n",
    "    df_raw['log_return'] = np.log(df_raw['close'] / df_raw['close'].shift(1))\n",
    "    \n",
    "    print(\"Returns Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Mean daily return: {df_raw['daily_return'].mean()*100:.4f}%\")\n",
    "    print(f\"Std daily return: {df_raw['daily_return'].std()*100:.4f}%\")\n",
    "    print(f\"Max daily return: {df_raw['daily_return'].max()*100:.2f}%\")\n",
    "    print(f\"Min daily return: {df_raw['daily_return'].min()*100:.2f}%\")\n",
    "    print(f\"Sharpe Ratio (approx): {(df_raw['daily_return'].mean() / df_raw['daily_return'].std()) * np.sqrt(365):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865296ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None:\n",
    "    # Distribution of returns\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(df_raw['daily_return'].dropna(), bins=100, edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0].set_xlabel('Daily Return')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Distribution of Daily Returns')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-Q plot\n",
    "    from scipy import stats\n",
    "    stats.probplot(df_raw['daily_return'].dropna(), dist=\"norm\", plot=axes[1])\n",
    "    axes[1].set_title('Q-Q Plot (Normality Check)')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fd01f",
   "metadata": {},
   "source": [
    "## 5. Fear & Greed Index Analysis\n",
    "\n",
    "Explore the sentiment indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None and 'fear_greed_value' in df_raw.columns:\n",
    "    print(\"Fear & Greed Index Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    print(df_raw['fear_greed_value'].describe())\n",
    "    print(\"\\nValue Classification Distribution:\")\n",
    "    print(df_raw['fear_greed_classification'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None and 'fear_greed_value' in df_raw.columns:\n",
    "    # Fear & Greed over time\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_raw['date'],\n",
    "        y=df_raw['fear_greed_value'],\n",
    "        mode='lines',\n",
    "        name='Fear & Greed',\n",
    "        line=dict(color='purple', width=2)\n",
    "    ))\n",
    "    \n",
    "    # Add zones\n",
    "    fig.add_hline(y=25, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Extreme Fear\")\n",
    "    fig.add_hline(y=75, line_dash=\"dash\", line_color=\"green\", annotation_text=\"Extreme Greed\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Fear & Greed Index Over Time',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Fear & Greed Value',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9a806",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis\n",
    "\n",
    "Understand relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0577574",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None:\n",
    "    # Select numeric columns\n",
    "    numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr = df_raw[numeric_cols].corr()\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix of Raw Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887d6ec",
   "metadata": {},
   "source": [
    "## 7. Volatility Analysis\n",
    "\n",
    "Crypto is known for volatility. Let's analyze it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b809481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_raw is not None:\n",
    "    # Calculate rolling volatility\n",
    "    df_raw['volatility_30d'] = df_raw['daily_return'].rolling(window=30).std() * np.sqrt(365) * 100\n",
    "    \n",
    "    # Plot\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=('BTC Close Price', '30-Day Rolling Volatility (Annualized)'),\n",
    "        row_heights=[0.5, 0.5]\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_raw['date'], y=df_raw['close'], name='Close Price', line=dict(color='blue')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_raw['date'], y=df_raw['volatility_30d'], name='Volatility', line=dict(color='red')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=700, title_text='Price vs Volatility')\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"\\nAverage annualized volatility: {df_raw['volatility_30d'].mean():.2f}%\")\n",
    "    print(f\"Max volatility: {df_raw['volatility_30d'].max():.2f}%\")\n",
    "    print(f\"Min volatility: {df_raw['volatility_30d'].min():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f7294",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering Preview\n",
    "\n",
    "Load and explore engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3145cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load featured data\n",
    "featured_file = os.path.join(PROCESSED_DATA_DIR, 'btc_usd_featured.csv')\n",
    "\n",
    "if os.path.exists(featured_file):\n",
    "    df_featured = pd.read_csv(featured_file)\n",
    "    df_featured['date'] = pd.to_datetime(df_featured['date'])\n",
    "    print(f\"‚úÖ Loaded featured data: {len(df_featured)} rows, {len(df_featured.columns)} features\")\n",
    "    display(df_featured.head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Featured data not found. Run feature_engineering.py first!\")\n",
    "    df_featured = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2562fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_featured is not None:\n",
    "    # Feature importance based on correlation with target\n",
    "    target = 'close'\n",
    "    feature_cols = [col for col in df_featured.columns if col not in ['date', target]]\n",
    "    \n",
    "    correlations = df_featured[feature_cols + [target]].corr()[target].drop(target).abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 20 features correlated with closing price:\")\n",
    "    print(\"=\"*60)\n",
    "    display(correlations.head(20))\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlations.head(20).plot(kind='barh')\n",
    "    plt.xlabel('Absolute Correlation with Close Price')\n",
    "    plt.title('Top 20 Features by Correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470de5ce",
   "metadata": {},
   "source": [
    "## 9. Key Insights\n",
    "\n",
    "**Summary of findings:**\n",
    "\n",
    "1. **Data Quality**: [Your observations here]\n",
    "2. **Price Trends**: [Your observations here]\n",
    "3. **Volatility Patterns**: [Your observations here]\n",
    "4. **Sentiment Relationship**: [Your observations here]\n",
    "5. **Feature Importance**: [Your observations here]\n",
    "\n",
    "**Next Steps:**\n",
    "- Complete feature engineering\n",
    "- Train LSTM model\n",
    "- Evaluate predictions\n",
    "- Build dashboard"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
